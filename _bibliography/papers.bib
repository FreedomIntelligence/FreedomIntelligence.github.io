---
---
@article{Zhao2024BBABB,
  title   = {BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models},
  author  = {Xueliang Zhao and Xinting Huang and Tingchen Fu and Qintong Li and Shansan Gong and Lemao Liu and Wei Bi and Lingpeng Kong},
  journal = {In Findings of the Annual Meeting of the Association for Computational Linguistics (ACL Findings)},
  year    = {2024},
  arxiv   = {2402.13577}
}

@article{Zhao2023SEGOSS,
  title   = {SEGO: Sequential Subgoal Optimization for Mathematical Problem-Solving},
  author  = {Xueliang Zhao and Xinting Huang and Wei Bi and Lingpeng Kong},
  journal = {In Proceedings of the
             Annual Meeting of the Association for Computational Linguistics (ACL)},
  year    = {2024},
  arxiv   = {2310.12960}
}

@article{Wang2023ACB,
  title   = {A Challenging Benchmark for Low-Resource Learning},
  author  = {Yudong Wang and Chang Ma and Qingxiu Dong and Lingpeng Kong and Jingjing Xu},
  journal = {In Findings of the Annual Meeting of the Association for Computational Linguistics (ACL Findings)},
  year    = {2024},
  arxiv   = {2303.03840}
}


@article{Wang2024LoRAMD,
  title   = {LoRA Meets Dropout under a Unified Framework},
  author  = {Sheng Wang and Liheng Chen and Jiyue Jiang and Boyang Xue and Lingpeng Kong and Chuan Wu},
  journal = {In Findings of the Annual Meeting of the Association for Computational Linguistics (ACL Findings)},
  year    = {2024},
  arxiv   = {2403.00812}
}


@article{Li2024GSMPlusAC,
  title   = {GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers},
  author  = {Qintong Li and Leyang Cui and Xueliang Zhao and Lingpeng Kong and Wei Bi},
  journal = {In Proceedings of the
             Annual Meeting of the Association for Computational Linguistics (ACL)},
  year    = {2024},
  arxiv   = {2402.19255}
}

@article{Wang2024PRoLoRAPR,
  title   = {PRoLoRA: Partial Rotation Empowers More Parameter-Efficient LoRA},
  author  = {Sheng Wang and Boyang Xue and Jiacheng Ye and Jiyue Jiang and Liheng Chen and Lingpeng Kong and Chuan Wu},
  journal = {In Proceedings of the
             Annual Meeting of the Association for Computational Linguistics (ACL)},
  year    = {2024},
  arxiv   = {2402.16902}
}

@article{An2023LEvalIS,
  title   = {L-Eval: Instituting Standardized Evaluation for Long Context Language Models},
  author  = {Chen An and Shansan Gong and Ming Zhong and Mukai Li and Jun Zhang and Lingpeng Kong and Xipeng Qiu},
  journal = {In Proceedings of the
             Annual Meeting of the Association for Computational Linguistics (ACL)},
  year    = {2024},
  arxiv   = {2307.11088}
}

@article{Li2024MultimodalAA,
  title   = {Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models},
  author  = {Lei Li and Yuqi Wang and Runxin Xu and Peiyi Wang and Xiachong Feng and Lingpeng Kong and Qi Liu},
  journal = {In Proceedings of the
             Annual Meeting of the Association for Computational Linguistics (ACL)},
  year    = {2024},
  arxiv   = {2403.00231}
}

@article{Zheng2023SelfInfillingCG,
  title   = {Self-Infilling Code Generation},
  author  = {Lin Zheng and Jianbo Yuan and Zhi Zhang and Hongxia Yang and Lingpeng Kong},
  journal = {In Proceedings of the International Conference on Machine Learning (ICML)},
  year    = {2024},
  arxiv   = {2311.17972},
  code    = {https://github.com/LZhengisme/self-infilling}
}

@article{Zhao2023DecomposingTE,
  title   = {Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving},
  author  = {Xueliang Zhao and Wenda Li and Lingpeng Kong},
  journal = {In Proceedings of the International Conference on Machine Learning (ICML)},
  year    = {2024},
  arxiv   = {2305.16366}
}

@article{Xu2023LemurHN,
  title   = {Lemur: Harmonizing Natural Language and Code for Language Agents},
  author  = {Yiheng Xu and Hongjin Su and Chen Xing and Boyu Mi and Qian Liu and Weijia Shi and Binyuan Hui and Fan Zhou and Yitao Liu and Tianbao Xie and Zhoujun Cheng and Siheng Zhao and Lingpeng Kong and Bailin Wang and Caiming Xiong and Tao Yu},
  journal = {In International Conference on Learning Representations (ICLR)},
  year    = {2024},
  arxiv   = {2310.06830},
  code    = {https://github.com/OpenLemur/Lemur}
}

@article{Li2023CanLM,
  title   = {Can Language Models Understand Physical Concepts?},
  author  = {Lei Li and Jingjing Xu and Qingxiu Dong and Ce Zheng and Qi Liu and Lingpeng Kong and Xu Sun},
  journal = {In Proceedings of the Conference on Empirical Methods in Natural Language
             Processing (EMNLP)},
  year    = {2023},
  arxiv   = {2305.14057},
  code    = {https://github.com/TobiasLee/VEC}
}

@article{Pi2023DetGPTDW,
  title   = {DetGPT: Detect What You Need via Reasoning},
  author  = {Renjie Pi and Jiahui Gao and Shizhe Diao and Rui Pan and Hanze Dong and Jipeng Zhang and Lewei Yao and Jianhua Han and Hang Xu and Lingpeng Kong Tong Zhang},
  journal = {In Proceedings of the Conference on Empirical Methods in Natural Language
             Processing (EMNLP)},
  year    = {2023},
  arxiv   = {2305.14167}
}

@article{Ye2023GeneratingDF,
  title   = {Generating Data for Symbolic Language with Large Language Models},
  author  = {Jiacheng Ye and Chengzu Li and Lingpeng Kong and Tao Yu},
  journal = {In Proceedings of the Conference on Empirical Methods in Natural Language
             Processing (EMNLP)},
  year    = {2023},
  arxiv   = {2305.13917},
  code    = {https://github.com/HKUNLP/SymGen}
}

@article{Gong2023DiffuSeqv2BD,
  title   = {DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated Seq2Seq Diffusion Models},
  author  = {Shansan Gong and Mukai Li and Jiangtao Feng and Zhiyong Wu and Lingpeng Kong},
  journal = {In Findings of the Conference on Empirical Methods in
             Natural Language Processing (EMNLP Findings)},
  year    = {2023},
  arxiv   = {2310.05793},
  code    = {https://github.com/Shark-NLP/DiffuSeq}
}

@article{Zhao2023GIMLETAU,
  title   = {GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning},
  author  = {Haiteng Zhao and Shengchao Liu and Chang Ma and Hannan Xu and Jie Fu and Zhihong Deng and Lingpeng Kong and Qi Liu},
  journal = {In Advances in Neural Information Processing Systems (NeurIPS)},
  year    = {2023},
  arxiv   = {2306.13089},
  code    = {https://github.com/zhao-ht/GIMLET}
}

@article{Dong2023StatisticalKA,
  title   = {Statistical Knowledge Assessment for Large Language Models},
  author  = {Qingxiu Dong and Jingjing Xu and Lingpeng Kong and Zhifang Sui and Lei Li},
  journal = {In Advances in Neural Information Processing Systems (NeurIPS)},
  year    = {2023},
  arxiv   = {2305.10519}
}

@article{Wu2022SelfAdaptiveIL,
  title   = {Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering},
  author  = {Zhiyong Wu and Yaoxiang Wang and Jiacheng Ye and Lingpeng Kong},
  journal = {In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year    = {2023},
  arxiv   = {2212.10375},
  code    = {https://github.com/Shark-NLP/self-adaptive-ICL}
}

@article{Li2022ExplanationRV,
  title   = {Explanation Regeneration via Information Bottleneck},
  author  = {Qintong Li and Zhiyong Wu and Lingpeng Kong and Wei Bi},
  journal = {In Findings of the Annual Meeting of the Association for Computational Linguistics (ACL Findings)},
  year    = {2023},
  arxiv   = {2212.09603}
}

@article{Jiang2023ACS,
  title   = {A Cognitive Stimulation Dialogue System with Multi-source Knowledge Fusion for Elders with Cognitive Impairment},
  author  = {Jiyue Jiang and Sheng Wang and Qintong Li and Lingpeng Kong and Chuan Wu},
  journal = {In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year    = {2023},
  arxiv   = {2305.08200}
}


@article{Ye2023CompositionalEF,
  title   = {Compositional Exemplars for In-context Learning},
  author  = {Jiacheng Ye and Zhiyong Wu and Jiangtao Feng and Tao Yu and Lingpeng Kong},
  journal = {In Proceedings of the International Conference on Machine Learning (ICML)},
  year    = {2023},
  arxiv   = {2302.05698},
  code    = {https://github.com/HKUNLP/icl-ceil}
}

@article{Zhang2022CABCA,
  title   = {CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling},
  author  = {Jinchao Zhang and Shuyang Jiang and Jiangtao Feng and Lin Zheng and Lingpeng Kong},
  journal = {In Proceedings of the International Conference on Machine Learning (ICML)},
  year    = {2023},
  arxiv   = {2210.07661},
  code    = {https://github.com/Shark-NLP/CAB}
}

@article{Zheng2023EfficientAV,
  title   = {Efficient Attention via Control Variates},
  author  = {Lin Zheng and Jianbo Yuan and Chong Wang and Lingpeng Kong},
  journal = {In International Conference on Learning Representations (ICLR)},
  year    = {2023},
  arxiv   = {2302.04542},
  code    = {https://github.com/HKUNLP/efficient-attention}
}

@article{Gong2022DiffuSeqST,
  title   = {DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models},
  author  = {Shansan Gong and Mukai Li and Jiangtao Feng and Zhiyong Wu and Lingpeng Kong},
  journal = {In International Conference on Learning Representations (ICLR)},
  year    = {2023},
  arxiv   = {2210.08933},
  code    = {https://github.com/Shark-NLP/DiffuSeq}
}

@article{Ye2022ProGenPZ,
  title   = {ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback},
  author  = {Jiacheng Ye and Jiahui Gao and Jiangtao Feng and Zhiyong Wu and Tao Yu and Lingpeng Kong},
  journal = {In Findings of the Conference on Empirical Methods in Natural Language Processing (EMNLP Findings)},
  year    = {2022},
  arxiv   = {2210.12329},
  code    = {https://github.com/HKUNLP/ProGen}
}


@article{su2022embedder,
  title   = {One Embedder, Any Task: Instruction-Finetuned Text Embeddings},
  author  = {Su, Hongjin and Shi, Weijia and Kasai, Jungo and Wang, Yizhong and Hu, Yushi and Ostendorf, Mari and Yih, Wen-tau and Smith, Noah A and Zettlemoyer, Luke and Yu, Tao},
  journal = {Preprint},
  year    = {2022},
  arxiv   = {2212.09741},
  code    = {https://github.com/HKUNLP/instructor-embedding},
  data    = {https://huggingface.co/hkunlp/instructor-large},
  poster  = {https://instructor-embedding.github.io}
}

@article{lai2022ds,
  title    = {DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation},
  author   = {Lai, Yuhang and Li, Chengxi and Wang, Yiming and Zhang, Tianyi and Zhong, Ruiqi and Zettlemoyer, Luke and Yih, Scott Wen-tau and Fried, Daniel and Wang, Sida and Yu, Tao},
  journal  = {Preprint},
  year     = {2022},
  arxiv    = {2211.11501},
  code     = {https://github.com/HKUNLP/DS-1000},
  poster   = {https://ds1000-code-gen.github.io/},
  data     = {https://github.com/HKUNLP/DS-1000/tree/main/ds1000_example},
  selected = {y}
}


@article{liu2022augmenting,
  title   = {Augmenting Multi-Turn Text-to-SQL Datasets with Self-Play},
  author  = {Liu, Qi and Ye, Zihuiwen and Yu, Tao and Blunsom, Phil and Song, Linfeng},
  journal = {Findings of EMNLP 2022},
  year    = {2022},
  note    = {Long Paper},
  arxiv   = {2210.12096},
  code    = {https://github.com/leuchine/self_play_picard}
}

@article{cheng2023binding,
  title    = {Binding Language Models in Symbolic Languages},
  author   = {Cheng, Zhoujun and Xie, Tianbao and Shi, Peng and Li, Chengzu and Nadkarni, Rahul and Hu, Yushi and Xiong, Caiming and Radev, Dragomir and Ostendorf, Mari and Zettlemoyer, Luke and Smith, Noah A and Yu, Tao},
  journal  = {International Conference on Learning Representations (ICLR)},
  location = {Berlin, Germany},
  year     = {2023},
  arxiv    = {2210.02875},
  code     = {https://lm-code-binder.github.io/},
  poster   = {https://lm-code-binder.github.io/},
  selected = {y}
}

@article{su2023selective,
  title   = {Selective Annotation Makes Language Models Better Few-Shot Learners},
  author  = {Su, Hongjin and Kasai, Jungo and Wu, Chen Henry and Shi, Weijia and Wang, Tianlu and Xin, Jiayi and Zhang, Rui and Ostendorf, Mari and Zettlemoyer, Luke and Smith, Noah A. and Yu, Tao},
  journal = {International Conference on Learning Representations (ICLR)},
  year    = {2023},
  arxiv   = {2209.01975},
  code    = {https://github.com/HKUNLP/icl-selective-annotation}
}

@article{wang2022evaluating,
  title   = {Evaluating Self-Supervised Learning for Molecular Graph Embeddings},
  author  = {Wang, Hanchen and Kaddour, Jean and Liu, Shengchao and Tang, Jian and Kusner, Matt and Lasenby, Joan and Liu, Qi},
  journal = {arXiv preprint arXiv:2206.08005},
  year    = {2022},
  arxiv   = {2206.08005}
}

@article{wang2022augmenting,
  title   = {Retrieval-enhanced Graph Neural Networks for Graph Property Prediction},
  author  = {Wang, Dingmin and Liu, Shengchao and Wang, Hanchen and Song, Linfeng and Tang, Jian and Le, Song and Grau, Bernardo Cuenca and Liu, Qi},
  journal = {arXiv preprint arXiv:2206.00362},
  year    = {2022},
  arxiv   = {2206.00362}
}

@article{ye2022zerogen,
  title   = {ZeroGen: Efficient Zero-shot Learning via Dataset Generation},
  author  = {Ye, Jiacheng and Gao, Jiahui and Li, Qintong and Xu, Hang and Feng, Jiangtao and Wu, Zhiyong and Yu, Tao and Kong, Lingpeng},
  journal = {Empirical Methods in Natural Language Processing (EMNLP)},
  year    = {2022},
  arxiv   = {2202.07922},
  code    = {https://github.com/jiacheng-ye/ZeroGen}
}

@article{xie2022unifiedskg,
  title   = {UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models},
  author  = {Xie, Tianbao and Wu, Chen Henry and Shi, Peng and Zhong, Ruiqi and Scholak, Torsten and Yasunaga, Michihiro and Wu, Chien-Sheng and Zhong, Ming and Yin, Pengcheng and Wang, Sida and Zhong, Victor and Wang, Bailin and Li, Chengzu and Boyle, Connor and Ni, Ansong and Yao, Ziyu and Radev, Dragomir and Xiong, Caiming and Kong, Lingpeng and Zhang, Rui and Smith, Noah A. and Zettlemoyer, Luke and Yu, Tao},
  journal = {Empirical Methods in Natural Language Processing (EMNLP)},
  year    = {2022},
  arxiv   = {2201.05966},
  code    = {https://github.com/hkunlp/unifiedskg},
  poster  = {https://unifiedskg.com/}
}

@article{zheng2021cascaded,
  title   = {Cascaded Head-colliding Attention},
  author  = {Lin Zheng and Zhiyong Wu and Lingpeng Kong},
  journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year    = {2021},
  arxiv   = {2105.14850},
  code    = {https://github.com/LZhengisme/CODA}
}

@article{wu2021good,
  title   = {Good for Misconceived Reasons: An Empirical Revisiting on the Need for Visual Context in Multimodal Machine Translation},
  author  = {Zhiyong Wu and Lingpeng Kong and Wei Bi and Xiang Li and Ben Kao},
  journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year    = {2021},
  arxiv   = {2105.14462},
  code    = {https://github.com/LividWo/Revisit-MMT}
}

@article{zheng2022linear,
  title   = {Linear Complexity Randomized Self-attention Mechanism},
  author  = {Lin Zheng and Chong Wang and Lingpeng Kong},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year    = {2022},
  arxiv   = {2204.04667},
  code    = {https://github.com/HKUNLP/efficient-attention}
}

@article{zheng2022ripple,
  title   = {Ripple Attention for Visual Perception with Sub-quadratic Complexity},
  author  = {Lin Zheng and Huijie Pan and Lingpeng Kong},
  journal = {Proceedings of the International Conference on Machine Learning (ICML)},
  year    = {2022},
  arxiv   = {2110.02453}
}

@article{prange2022linguistic,
  title   = {Linguistic Frameworks Go Toe-to-Toe at Neuro-Symbolic Language Modeling},
  author  = {Jakob Prange and Nathan Schneider and Lingpeng Kong},
  journal = {Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year    = {2022},
  arxiv   = {2112.07874},
  code    = {https://github.com/jakpra/LinguisticStructureLM}
}

@article{li2022event,
  title   = {Event Transition Planning for Open-ended Text Generation},
  author  = {Qintong Li and Piji Li and Wei Bi and Zhaochun Ren and Yuxuan Lai and Lingpeng Kong},
  journal = {Findings of the Annual Meeting of the Association for Computational Linguistics (ACL Findings)},
  year    = {2022},
  arxiv   = {2204.09453},
  code    = {https://github.com/qtli/EventPlanforTextGen}
}

@article{wu2022lexical,
  title   = {Lexical Knowledge Internalization for Neural Dialog Generation},
  author  = {Zhiyong Wu and Wei Bi and Xiang Li and Lingpeng Kong and Ben Kao},
  journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)},
  year    = {2022},
  arxiv   = {2205.01941},
  code    = {https://github.com/LividWo/KI}
}



@article{gao2023selfguided,
  title    = {Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning},
  author   = {Jiahui Gao and Renjie Pi and Lin Yong and Hang Xu and Jiacheng Ye and Zhiyong Wu and Weizhong Zhang and Xiaodan Liang and Zhenguo Li and Lingpeng Kong},
  journal  = {International Conference on Learning Representations (ICLR)},
  location = {Kigali, Rwanda},
  year     = {2023},
  arxiv    = {2205.12679},
  code     = {https://github.com/SumilerGAO/SunGen}
}

@article{chen2023unsupervised,
  title    = {Unsupervised Explanation Generation via Correct Instantiations},
  author   = {Sijie Chen and Zhiyong Wu and Jiangjie Chen and Zhixing Li and Yang Liu and Lingpeng Kong},
  journal  = {Proceedings of AAAI Conference on Artificial Intelligence (AAAI)},
  location = {Washington, DC},
  year     = {2023},
  arxiv    = {2211.11160},
  code     = {https://github.com/Shark-NLP/Neon}
}

@article{ma2023retrieved,
  title   = {Retrieved Sequence Augmentation for Protein Representation Learning},
  author  = {Chang Ma and Haiteng Zhao and Lin Zheng and Jiayi Xin and Qintong Li and Lijun Wu and Zhihong Deng and Yang Lu and Qi Liu and Lingpeng Kong},
  journal = {arXiv preprint arXiv:2302.12563},
  year    = {2023},
  arxiv   = {2302.12563},
  code    = {https://github.com/HKUNLP/RSA}
}

@article{zheng2023reparameterized,
  title   = {A Reparameterized Discrete Diffusion Model for Text Generation},
  author  = {Lin Zheng and Jianbo Yuan and Lei Yu and Lingpeng Kong},
  journal = {arXiv preprint arXiv:2302.04542},
  year    = {2023},
  arxiv   = {2302.04542},
  code    = {https://github.com/HKUNLP/reparam-discrete-diffusion}
}



